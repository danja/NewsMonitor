<?xml version="1.0" encoding="UTF-8"?><rdf:RDF
	xmlns="http://purl.org/rss/1.0/"
	xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:admin="http://webns.net/mvcb/"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	>
<channel rdf:about="http://ebiquity.umbc.edu/blogger">
	<title>UMBC ebiquity &#187; Semantic Web</title>
	<link>http://ebiquity.umbc.edu/blogger</link>
	<description>EBB is the ebiquity research group\\\'s blog at the University of Maryland, Baltimore County (UMBC).  We focus on technologies that facilitate the design, implementation and control of distributed, intelligent information systems -- mobile and pervasive computing, ad hoc networking, multiagent systems, knowledge representation and reasoning, and the semantic web.  As the tides of technology ebb and flow, we hope the good ideas wash up on our beach and the bad ones drift back out to sea.</description>
	<dc:date>2014-04-09T15:05:53Z</dc:date>
		<sy:updatePeriod>hourly</sy:updatePeriod>
		<sy:updateFrequency>1</sy:updateFrequency>
	<sy:updateBase>2000-01-01T12:00+00:00</sy:updateBase>
	<admin:generatorAgent rdf:resource="http://wordpress.org/?v=3.8.3" />
	<items>
		<rdf:Seq>
					<rdf:li rdf:resource="http://ebiquity.umbc.edu/blogger/2014/03/27/dont-be-a-glhole-use-faceblock/"/>
					<rdf:li rdf:resource="http://ebiquity.umbc.edu/blogger/2014/02/26/stardog-unleashed-md-semantic-web-meeup-6pm-thr-227/"/>
					<rdf:li rdf:resource="http://ebiquity.umbc.edu/blogger/2014/02/08/tracking-provenance-and-reproducibility-of-big-data-experiments/"/>
					<rdf:li rdf:resource="http://ebiquity.umbc.edu/blogger/2014/01/30/jan-30-ontology-summit-tools-services-and-techniques/"/>
					<rdf:li rdf:resource="http://ebiquity.umbc.edu/blogger/2014/01/23/ontology-summit-use-and-reuse-of-semantic-content/"/>
					<rdf:li rdf:resource="http://ebiquity.umbc.edu/blogger/2014/01/18/free-copy-of-mining-massive-datasets/"/>
					<rdf:li rdf:resource="http://ebiquity.umbc.edu/blogger/2014/01/14/2014-ontology-summit-big-data-and-semantic-web-meet-applied-ontology/"/>
					<rdf:li rdf:resource="http://ebiquity.umbc.edu/blogger/2014/01/09/yunsu-lee-phd-proposal-functional-reference-ontology-development/"/>
					<rdf:li rdf:resource="http://ebiquity.umbc.edu/blogger/2014/01/01/google-knowledge-maps-demonstration/"/>
					<rdf:li rdf:resource="http://ebiquity.umbc.edu/blogger/2013/05/23/googles-top-charts-uses-the-knowledge-graph-for-entity-recognition/"/>
				</rdf:Seq>
	</items>
</channel>
<item rdf:about="http://ebiquity.umbc.edu/blogger/2014/03/27/dont-be-a-glhole-use-faceblock/">
	<title>Do not be a Gl***hole, use Face-Block.me!</title>
	<link>http://ebiquity.umbc.edu/blogger/2014/03/27/dont-be-a-glhole-use-faceblock/</link>
	<dc:date>2014-03-27T18:13:20Z</dc:date>
	<dc:creator><![CDATA[Prajit Kumar Das]]></dc:creator>
			<dc:subject><![CDATA[Ebiquity]]></dc:subject>
		<dc:subject><![CDATA[Google]]></dc:subject>
		<dc:subject><![CDATA[Mobile Computing]]></dc:subject>
		<dc:subject><![CDATA[Policy]]></dc:subject>
		<dc:subject><![CDATA[Semantic Web]]></dc:subject>
		<dc:subject><![CDATA[Social]]></dc:subject>
		<dc:subject><![CDATA[Wearable Computing]]></dc:subject>
		<dc:subject><![CDATA[Google Glass]]></dc:subject>
		<dc:subject><![CDATA[Privacy-aware pictures]]></dc:subject>
	<description><![CDATA[Faceblock is a prototype app for Google Glass and mobile devices that informs Glass to blur the faces of people in its immediate vicinity whose privacy policies request it.]]></description>
	<content:encoded><![CDATA[<div id="tweetbutton4813" class="tw_button" style="clear:left; float: left; margin-right: 10px; margin-top:10px; margin-left: -80;float:left;margin-right:10px;"><a href="http://twitter.com/share?url=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F03%2F27%2Fdont-be-a-glhole-use-faceblock%2F&amp;text=Check%20out%20FaceBlock%20a%20cool%20new%20app%20to%20take%20privacy-aware%20pictures.%20http%3A%2F%2Fwww.face-block.me&amp;related=Face_Block:Privacy-aware%20pictures%20for%20mobile%20devices&amp;lang=en&amp;count=vertical&amp;counturl=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F03%2F27%2Fdont-be-a-glhole-use-faceblock%2F" class="twitter-share-button"  style="width:55px;height:22px;background:transparent url('http://ebiquity.umbc.edu/blogger/wp-content/plugins/wp-tweet-button/tweetn.png') no-repeat  0 0;text-align:left;text-indent:-9999px;display:block;">Tweet</a></div><p style="text-align: justify;">If you are a Google Glass user, you might have been greeted with concerned looks or raised eyebrows at public places. There has been a lot of chatter in the &#8220;interweb&#8221; regarding the loss of privacy that results from people taking your pictures with Glass without notice. Google Glass has simplified photography but as what happens with revolutionary technology people are worried about the potential misuse.</p>
<p style="text-align: justify;">FaceBlock helps to protect the privacy of people around you by allowing them to specify whether or not to be included in your pictures.Â This new application developed by the joint collaboration between researchers from theÂ <a href="http://ebiquity.umbc.edu/">Ebiquity Research Group</a>Â at University ofÂ Maryland, Baltimore County and <a href="http://sid.cps.unizar.es/">Distributed Information Systems (DIS)</a> at University of Zaragoza (Spain), selectively obscures the face of the people in pictures taken by Google Glass.</p>
<h2 style="text-align: justify;">Comfort at the cost of Privacy?</h2>
<p style="text-align: justify;">As the saying goes, &#8220;The best camera is the one that&#8217;s with you&#8221;. Google Glass suits this description as it is always available and can take a picture with a simple voice command (&#8220;Okay Glass, take a picture&#8221;). This allows users to capture spontaneous life moments effortlessly. On the flip side, this raises significant privacy concerns as pictures can taken without one&#8217;s consent. If one does not use this device responsibly, one risks being labelled a &#8220;Glasshole&#8221;. Quite recently, <a href="http://sanfrancisco.cbslocal.com/2014/02/25/woman-wearing-google-glass-says-she-was-attacked-in-san-francisco-bar/">a Google Glass user was assaulted by the patrons</a> whoÂ objected against her wearing the device inside the bar. The <a href="http://www.glasshole-free.org/">list of establishments</a> which has bannedÂ Google Glass within their premises is growing day by day. The <a href="https://sites.google.com/site/glasscomms/glass-explorers">dos and donts</a>Â for Glass users released by Google is a good first step but it doesn&#8217;t solve the problem of privacy violation.</p>
<div style="width: 501px; height: 251px; margin: 0px auto; text-align: justify;"><a href="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/03/image_gg_1.png"><img class="size-medium wp-image-4818 aligncenter" alt="FaceBlock_Image_Google_Glass" src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/03/image_gg_1.png" width="501" height="251" /></a></div>
<h2 style="text-align: justify;">Privacy-Aware pictures to the rescue</h2>
<p style="text-align: justify;">FaceBlock takes regular pictures taken by your smartphone or Google Glass as input and converts it into <strong>privacy-aware pictures</strong>. This outputÂ is generated by using a combination of Face Detection and Face Recognition algorithms. By using FaceBlock, a userÂ can take a picture of herself and specify her policy/rule regarding pictures taken by others (in this case &#8216;obscure my face in pictures fromÂ strangers&#8217;). The application would automatically generate a face identifier for this picture. The identifier is a mathematical representation of the image. To learn more about the working on FaceBlock, you should watch the following video.</p>
<div style="width: 501px; height: 283px; margin: 0px auto; text-align: justify;"><iframe src="//www.youtube.com/embed/IseoIWNWiR8" height="283" width="501" allowfullscreen="" frameborder="0" align="center"></iframe></div>
<p style="text-align: justify;">Using <a href="http://en.wikipedia.org/wiki/Bluetooth">Bluetooth</a>, FaceBlock can automatically detect and share this policy with Glass users near by. After receiving this face identifier from a nearby user, the following post processing steps happen on Glass as shown in the images.</p>
<div style="width: 501px; height: 92px; margin: 0px auto; text-align: justify;"><a href="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/03/image_eig_1.png"><img class="alignnone size-medium wp-image-4816" alt="FaceBlock_Image_Eigen_Uncheck" src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/03/image_eig_1.png" width="166" height="92" /></a><a href="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/03/image_eig_2.png"><img class="alignnone size-medium wp-image-4817" alt="FaceBlock_Image_Eigen_Check" src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/03/image_eig_2.png" width="166" height="92" /></a><a href="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/03/image_blur_1.png"><img class="alignnone size-medium wp-image-4815 alignleft" alt="FaceBlock_Image_Blur" src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/03/image_blur_1.png" width="166" height="92" /></a></div>
<h2 style="text-align: justify;">What promises does it hold?</h2>
<p style="text-align: justify;">FaceBlock is a proof of concept implementation of a system that can create <strong>privacy-aware pictures</strong> using smart devices. The pervasiveness of <strong>privacy-aware pictures</strong> could be a right step towards balancing privacy needs and comfort afforded by technology. Thus, we can get the best out of Wearable Technology without being oblivious about the privacy of those around you.</p>
<p style="text-align: justify;">FaceBlock is part of the efforts of Ebiquity and SID in building systems for preserving user privacy on mobile devices. For more details, visit <a title="FaceBlock" href="http://www.face-block.me" target="_blank">http://face-block.me</a></p>
]]></content:encoded>
	</item>
<item rdf:about="http://ebiquity.umbc.edu/blogger/2014/02/26/stardog-unleashed-md-semantic-web-meeup-6pm-thr-227/">
	<title>Stardog unleashed: MD Semantic Web Meeup, 6pm Thr 2/27</title>
	<link>http://ebiquity.umbc.edu/blogger/2014/02/26/stardog-unleashed-md-semantic-web-meeup-6pm-thr-227/</link>
	<dc:date>2014-02-26T18:12:06Z</dc:date>
	<dc:creator><![CDATA[Tim Finin]]></dc:creator>
			<dc:subject><![CDATA[Semantic Web]]></dc:subject>
	<description><![CDATA[Tweet The next Central MD Semantic Web Meetup will be held at 6:00pm on Thursday, February 27, 2014 at Inovex Information Systems (7240 Parkway Dr., Suite 140, Hanover MD). Michael Grove, the Chief Software Architect at Clark &#38; Parsia, will talk on their Stardog triple store technology. The meetup is a good way to meet [&#8230;]]]></description>
	<content:encoded><![CDATA[<div id="tweetbutton4799" class="tw_button" style="clear:left; float: left; margin-right: 10px; margin-top:10px; margin-left: -80;float:left;margin-right:10px;"><a href="http://twitter.com/share?url=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F02%2F26%2Fstardog-unleashed-md-semantic-web-meeup-6pm-thr-227%2F&amp;text=Stardog%20unleashed%3A%20MD%20Semantic%20Web%20Meeup%2C%206pm%20Thr%202%2F27&amp;related=ebiquity&amp;lang=en&amp;count=vertical&amp;counturl=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F02%2F26%2Fstardog-unleashed-md-semantic-web-meeup-6pm-thr-227%2F" class="twitter-share-button"  style="width:55px;height:22px;background:transparent url('http://ebiquity.umbc.edu/blogger/wp-content/plugins/wp-tweet-button/tweetn.png') no-repeat  0 0;text-align:left;text-indent:-9999px;display:block;">Tweet</a></div><p><img src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/02/stardog@2x-copy.png" alt="" width="500" height="286" class="alignnone size-full wp-image-4802" border="1" /></p>
<p>The next <a href="http://www.meetup.com/MarylandSemantics/events/163753242/?a=md1_grp&amp;rv=md1&amp;_af_eid=163753242&amp;_af=event">Central MD Semantic Web Meetup</a> will be held at 6:00pm on Thursday, February 27, 2014 at Inovex Information Systems (7240 Parkway Dr., Suite 140, Hanover MD). Michael Grove, the Chief Software Architect at Clark &amp; Parsia, will talk on their Stardog triple store technology. The meetup is a good way to meet and network with others working on or with semantic technologies in Maryland.</p>
<p>&#8220;Stardog Unleashed will provide some background on the motivation for building <a href="http://stardog.com/" target="_blank">Stardog</a>, as well a short review of its history and unique feature set We will also provide an overview and demo of Stardog Web; a Javascript framework for building web applications backed by semantic technologies.</p>
<p>Our speaker, Michael Grove, is the Chief Software Architect at <a href="http://clarkparsia.com/" target="_blank">Clark &amp; Parsia</a>, where he also serves as the lead developer of Stardog, the leader in RDF databases featuring fast query performance and unmatched OWL &amp; SWRL support.</p>
<p>A graduate in Computer Science at the University of Maryland, College Park, Michael first got started with semantic technologies in 2002 as a research assistant under Dr. Jim Hendler at the University of Maryland with the MINDSWAP group. Before joining the team at Clark &amp; Parsia, he worked at Fujitsu Research Labs as the lead developer for the Task Computing project, an effort bring the semantic web to pervasive computing environments.</p>
<p>Michael is also active in open source where he is a contributor to <a href="http://clarkparsia.com/pellet/" target="_blank">Pellet</a> the leading OWL DL reasoner and maintains Empire, an implementation of JPA backed by semantic technologies. Additionally, he is contributor to the Sesame project and active on the Jena development list.&#8221;</p>
]]></content:encoded>
	</item>
<item rdf:about="http://ebiquity.umbc.edu/blogger/2014/02/08/tracking-provenance-and-reproducibility-of-big-data-experiments/">
	<title>Tracking Provenance and Reproducibility of Big Data Experiments</title>
	<link>http://ebiquity.umbc.edu/blogger/2014/02/08/tracking-provenance-and-reproducibility-of-big-data-experiments/</link>
	<dc:date>2014-02-08T16:53:45Z</dc:date>
	<dc:creator><![CDATA[Tim Finin]]></dc:creator>
			<dc:subject><![CDATA[Big data]]></dc:subject>
		<dc:subject><![CDATA[High performance computing]]></dc:subject>
		<dc:subject><![CDATA[Ontologies]]></dc:subject>
		<dc:subject><![CDATA[Semantic Web]]></dc:subject>
	<description><![CDATA[Vlad Korolev talks about his research on using RDF to capture, represent and use provenance information for big data experiments at 10:00am Monday, February 10 in room 346 of the ITE building at UMBC.]]></description>
	<content:encoded><![CDATA[<div id="tweetbutton4789" class="tw_button" style="clear:left; float: left; margin-right: 10px; margin-top:10px; margin-left: -80;float:left;margin-right:10px;"><a href="http://twitter.com/share?url=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F02%2F08%2Ftracking-provenance-and-reproducibility-of-big-data-experiments%2F&amp;text=Tracking%20Provenance%20and%20Reproducibility%20of%20Big%20Data%20Experiments&amp;related=ebiquity&amp;lang=en&amp;count=vertical&amp;counturl=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F02%2F08%2Ftracking-provenance-and-reproducibility-of-big-data-experiments%2F" class="twitter-share-button"  style="width:55px;height:22px;background:transparent url('http://ebiquity.umbc.edu/blogger/wp-content/plugins/wp-tweet-button/tweetn.png') no-repeat  0 0;text-align:left;text-indent:-9999px;display:block;">Tweet</a></div><p><img src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/02/prov.png" alt="" width="500" height="266" class="alignnone size-full wp-image-4790" /></p>
<p>In the first Ebiquity meeting of the semester, <a href="http://ebiquity.umbc.edu/person/html/Vladimir/Korolev/">Vlad Korolev</a> will talk about his work on using RDF for to capture, represent and use provenance information for big data experiments.</p>
<h3>PROB: A tool for Tracking Provenance and Reproducibility of Big Data Experiments</h3>
<p><strong>10-11:30am, ITE346, UMBC</strong></p>
<p>Reproducibility of computations and data provenance are very important goals to achieve in order to improve the quality of one&#8217;s research.  Unfortunately, despite some efforts made in the past, it is still very hard to reproduce computational experiments with high degree of certainty.  The Big Data phenomenon in recent years makes this goal even harder to achieve.  In this work, we propose a tool that aids researchers to improve reproducibility of their experiments through automated keeping of provenance records.</p>
]]></content:encoded>
	</item>
<item rdf:about="http://ebiquity.umbc.edu/blogger/2014/01/30/jan-30-ontology-summit-tools-services-and-techniques/">
	<title>Jan 30 Ontology Summit: Tools, Services, and Techniques</title>
	<link>http://ebiquity.umbc.edu/blogger/2014/01/30/jan-30-ontology-summit-tools-services-and-techniques/</link>
	<dc:date>2014-01-30T15:34:09Z</dc:date>
	<dc:creator><![CDATA[Tim Finin]]></dc:creator>
			<dc:subject><![CDATA[KR]]></dc:subject>
		<dc:subject><![CDATA[Ontologies]]></dc:subject>
		<dc:subject><![CDATA[Semantic Web]]></dc:subject>
	<description><![CDATA[Tweet Today&#8217;s online meeting (Jan 30, 12:30-2:30 EST) in the 2014 Ontology Summit series is part of the Tools, Services, and Techniques track and features presentations by Dr. ChrisWelty (IBM Research) on &#8220;Inside the Mind of Watson â a Natural Language Question Answering Service Powered by the Web of Data and Ontologies&#8221; Prof. AlanRector (U. [&#8230;]]]></description>
	<content:encoded><![CDATA[<div id="tweetbutton4784" class="tw_button" style="clear:left; float: left; margin-right: 10px; margin-top:10px; margin-left: -80;float:left;margin-right:10px;"><a href="http://twitter.com/share?url=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F30%2Fjan-30-ontology-summit-tools-services-and-techniques%2F&amp;text=Jan%2030%20Ontology%20Summit%3A%20Tools%2C%20Services%2C%20and%20Techniques&amp;related=ebiquity&amp;lang=en&amp;count=vertical&amp;counturl=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F30%2Fjan-30-ontology-summit-tools-services-and-techniques%2F" class="twitter-share-button"  style="width:55px;height:22px;background:transparent url('http://ebiquity.umbc.edu/blogger/wp-content/plugins/wp-tweet-button/tweetn.png') no-repeat  0 0;text-align:left;text-indent:-9999px;display:block;">Tweet</a></div><p><img src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/01/Watson3_610x478.jpg" alt="" width="500" height="281" class="alignnone size-full wp-image-4785" /></p>
<p>Today&#8217;s <a href="http://bit.ly/osum130">online meeting</a> (Jan 30, 12:30-2:30 EST) in the 2014 Ontology Summit series is part of the Tools, Services, and Techniques track and features presentations by</p>
<ul>
<li> Dr. ChrisWelty (IBM Research) on &#8220;Inside the Mind of Watson â a Natural Language Question Answering Service Powered by the Web of Data and Ontologies&#8221;</li>
<li> Prof. AlanRector (U. Manchester) on &#8220;Axioms &#038; Templates: Distinctions and Transformations amongst Ontologies, Frames, &#038; Information Models</li>
<li> Professor TillMossakowski (U. Magdeburg) on &#8220;Challenges in Scaling Tools for Ontologies to the Semantic Web: Experiences with Hets and OntoHub&#8221;</li>
</ul>
<p>Audio via phone (206-402-0100) or Skype.  See the <a href="http://bit.ly/osum130">session page</a> for details and access to slides.</p>
]]></content:encoded>
	</item>
<item rdf:about="http://ebiquity.umbc.edu/blogger/2014/01/23/ontology-summit-use-and-reuse-of-semantic-content/">
	<title>Ontology Summit: Use and Reuse of Semantic Content</title>
	<link>http://ebiquity.umbc.edu/blogger/2014/01/23/ontology-summit-use-and-reuse-of-semantic-content/</link>
	<dc:date>2014-01-23T13:48:47Z</dc:date>
	<dc:creator><![CDATA[Tim Finin]]></dc:creator>
			<dc:subject><![CDATA[KR]]></dc:subject>
		<dc:subject><![CDATA[Ontologies]]></dc:subject>
		<dc:subject><![CDATA[Semantic Web]]></dc:subject>
	<description><![CDATA[Tweet The first online session of the 2014 Ontology Summit on &#8220;Big Data and Semantic Web Meet Applied Ontology&#8221; takes place today (Thurday January 23) from 12:30pm to 2:30pm (EST, UTC-5) with topic Common Reusable Semantic Content &#8212; The Problems and Efforts to Address Them. The session will include four presentations: Gary Berg Cross, Use [&#8230;]]]></description>
	<content:encoded><![CDATA[<div id="tweetbutton4776" class="tw_button" style="clear:left; float: left; margin-right: 10px; margin-top:10px; margin-left: -80;float:left;margin-right:10px;"><a href="http://twitter.com/share?url=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F23%2Fontology-summit-use-and-reuse-of-semantic-content%2F&amp;text=Ontology%20Summit%3A%20Use%20and%20Reuse%20of%20Semantic%20Content&amp;related=ebiquity&amp;lang=en&amp;count=vertical&amp;counturl=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F23%2Fontology-summit-use-and-reuse-of-semantic-content%2F" class="twitter-share-button"  style="width:55px;height:22px;background:transparent url('http://ebiquity.umbc.edu/blogger/wp-content/plugins/wp-tweet-button/tweetn.png') no-repeat  0 0;text-align:left;text-indent:-9999px;display:block;">Tweet</a></div><p><img src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/01/Screen-Shot-2014-01-23-at-8.44.46-AM.png" alt="" width="500" height="362" class="alignnone size-full wp-image-4778" border="1" /></p>
<p>The first online session of the <a href="http://ebiquity.umbc.edu/blogger/2014/01/14/2014-ontology-summit-big-data-and-semantic-web-meet-applied-ontology/">2014 Ontology Summit</a> on &#8220;Big Data and Semantic Web Meet Applied Ontology&#8221; takes place today (Thurday January 23) from 12:30pm to 2:30pm (EST, UTC-5) with topic <a href="http://ontolog.cim3.net/cgi-bin/wiki.pl?ConferenceCall_2014_01_23">Common Reusable Semantic Content &#8212; The Problems and Efforts to Address Them</a>.  The session will include four presentations:</p>
<ul>
<li>Gary Berg Cross, <a href="http://ontolog.cim3.net/file/work/OntologySummit2014/2014-01-23_OntologySummit2014_Common-Reusable-Semantic-Content-1/OntologySummit2014-s02_Use-and-Reuse-of-Semantic-Content--GaryBergCross_20140123.pdf">Use and Reuse of Semantic Content: The Problems and Efforts to Address Them &#8211; An Introduction</a></li>
<li>Pascal Hitzler, <a href="http://ontolog.cim3.net/file/work/OntologySummit2014/2014-01-23_OntologySummit2014_Common-Reusable-Semantic-Content-1/OntologySummit2014-s02_Towards-ontology-patterns-for-ocean-science-repository-integration--PascalHitzler_20140123.pdf">Towards ontology patterns for ocean science repository integration</a></li>
<li>Andrea Westerinen, <a href="http://ontolog.cim3.net/file/work/OntologySummit2014/2014-01-23_OntologySummit2014_Common-Reusable-Semantic-Content-1/OntologySummit2014-s02_Reuse_ISO15926-FIBO--AndreaWesterinen_20140123.pdf">Reuse of Content from ISO 15926 and FIBO</a></li>
<li>Megan Katsumi and Michael Gruninger, <a href="http://ontolog.cim3.net/file/work/OntologySummit2014/2014-01-23_OntologySummit2014_Common-Reusable-Semantic-Content-1/OntologySummit2014-s02_Reasoning-about-Events-on-SemanticWeb--MeganKatsumi-MichaelGruninger_20140123.pdf">Reasoning about Events on the Semantic Web</a></li>
</ul>
<p>followed by discussion.</p>
<p>Audio connection is via phone (206-402-0100, 141184#) or Skype with a shared screen and participant chatroom. See the <a href="http://ontolog.cim3.net/cgi-bin/wiki.pl?ConferenceCall_2014_01_23">session page</a> for more details.</p>
]]></content:encoded>
	</item>
<item rdf:about="http://ebiquity.umbc.edu/blogger/2014/01/18/free-copy-of-mining-massive-datasets/">
	<title>Free copy of Mining Massive Datasets</title>
	<link>http://ebiquity.umbc.edu/blogger/2014/01/18/free-copy-of-mining-massive-datasets/</link>
	<dc:date>2014-01-18T06:56:01Z</dc:date>
	<dc:creator><![CDATA[Tim Finin]]></dc:creator>
			<dc:subject><![CDATA[Big data]]></dc:subject>
		<dc:subject><![CDATA[Datamining]]></dc:subject>
		<dc:subject><![CDATA[Machine Learning]]></dc:subject>
		<dc:subject><![CDATA[Semantic Web]]></dc:subject>
	<description><![CDATA[Tweet A free PDF version of the new second edition of Mining of Massive Datasets by Anand Rajaraman, Jure Leskovec and Jeffey Ullman is available. New chapters on mining large graphs, dimensionality reduction, and machine learning have been added. Related material from Professor Leskovec&#8217;s recent Stanford course on Mining Massive Data Sets is also available.]]></description>
	<content:encoded><![CDATA[<div id="tweetbutton4773" class="tw_button" style="clear:left; float: left; margin-right: 10px; margin-top:10px; margin-left: -80;float:left;margin-right:10px;"><a href="http://twitter.com/share?url=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F18%2Ffree-copy-of-mining-massive-datasets%2F&amp;text=Free%20copy%20of%20Mining%20Massive%20Datasets&amp;related=ebiquity&amp;lang=en&amp;count=vertical&amp;counturl=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F18%2Ffree-copy-of-mining-massive-datasets%2F" class="twitter-share-button"  style="width:55px;height:22px;background:transparent url('http://ebiquity.umbc.edu/blogger/wp-content/plugins/wp-tweet-button/tweetn.png') no-repeat  0 0;text-align:left;text-indent:-9999px;display:block;">Tweet</a></div><p><img src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/01/12818088.jpg" alt="" width="500" height="281" class="alignnone size-full wp-image-4774" /></p>
<p>A free PDF version of the new second edition of <a href="http://i.stanford.edu/~ullman/mmds.html">Mining of Massive Datasets</a> by Anand Rajaraman, Jure Leskovec and Jeffey Ullman is available.  New chapters on mining large graphs, dimensionality reduction, and machine learning have been added.  Related material from Professor Leskovec&#8217;s recent Stanford course on <a href="http://www.stanford.edu/class/cs246/">Mining Massive Data Sets</a> is also available.</p>
]]></content:encoded>
	</item>
<item rdf:about="http://ebiquity.umbc.edu/blogger/2014/01/14/2014-ontology-summit-big-data-and-semantic-web-meet-applied-ontology/">
	<title>2014 Ontology Summit: Big Data and Semantic Web Meet Applied Ontology</title>
	<link>http://ebiquity.umbc.edu/blogger/2014/01/14/2014-ontology-summit-big-data-and-semantic-web-meet-applied-ontology/</link>
	<dc:date>2014-01-14T15:30:47Z</dc:date>
	<dc:creator><![CDATA[Tim Finin]]></dc:creator>
			<dc:subject><![CDATA[Big data]]></dc:subject>
		<dc:subject><![CDATA[KR]]></dc:subject>
		<dc:subject><![CDATA[Ontologies]]></dc:subject>
		<dc:subject><![CDATA[Semantic Web]]></dc:subject>
	<description><![CDATA[The ninth Ontology Summit starts on Thursday, January 16 with the theme "Big Data and Semantic Web Meet Applied Ontology."  The event kicks off a free three month series of weekly online meetings with presentations from experts and  culminates with a two day symposium on April 28-29 in Arlington VA.  ]]></description>
	<content:encoded><![CDATA[<div id="tweetbutton4765" class="tw_button" style="clear:left; float: left; margin-right: 10px; margin-top:10px; margin-left: -80;float:left;margin-right:10px;"><a href="http://twitter.com/share?url=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F14%2F2014-ontology-summit-big-data-and-semantic-web-meet-applied-ontology%2F&amp;text=2014%20Ontology%20Summit%3A%20Big%20Data%20and%20Semantic%20Web%20Meet%20Applied%20Ontology&amp;related=ebiquity&amp;lang=en&amp;count=vertical&amp;counturl=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F14%2F2014-ontology-summit-big-data-and-semantic-web-meet-applied-ontology%2F" class="twitter-share-button"  style="width:55px;height:22px;background:transparent url('http://ebiquity.umbc.edu/blogger/wp-content/plugins/wp-tweet-button/tweetn.png') no-repeat  0 0;text-align:left;text-indent:-9999px;display:block;">Tweet</a></div><p><img src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/01/lod1.png" alt="lod" width="500" height="281" class="alignnone size-full wp-image-4768" /></p>
<p>The ninth <a href="http://bit.ly/osum14">Ontology Summit</a> starts on Thursday, January 16 with the theme &#8220;Big Data and Semantic Web Meet Applied Ontology.&#8221;  The event kicks off a three month series of weekly online meetings on Thursdays that feature presentations from expert panels and discussions with all of the participants.  The series will culminate with a two day symposium on April 28-29 in Arlington VA.  The sessions are free and open to all, including researchers, practitioners and students.</p>
<p>The <a href="http://ontolog.cim3.net/cgi-bin/wiki.pl?ConferenceCall_2014_01_16">first virtual meeting</a> will be held 12:30-<strike>2:00</strike> <span style="color:red">2:30</span> (EST) on Thursday, January 16 and will introduce the nine different topical tracks in the series, their goals and organizers.  Audio connection is via phone (206-402-0100, 141184#) or Skype with a shared screen and participant chatroom.  See the <a href="http://ontolog.cim3.net/cgi-bin/wiki.pl?ConferenceCall_2014_01_16">session page</a> for more details.</p>
<p>This year&#8217;s Ontology Summit is an opportunity for building bridges between the Semantic Web, Linked Data, Big Data, and Applied Ontology communities. On the one hand, the Semantic Web, Linked Data, and Big Data communities can bring a wide array of real problems (such as performance and scalability challenges and the variety problem in Big Data) and technologies (automated reasoning tools) that can make use of ontologies. On the other hand, the Applied Ontology community can bring a large body of common reusable content (ontologies) and ontological analysis techniques. Identifying and overcoming ontology engineering bottlenecks is critical for all communities.</p>
</p>
<p>The 2014 Ontology Summit is chaired by <a href="http://ontolog.cim3.net/cgi-bin/wiki.pl?MichaelGruninger">Michael Gruninger</a> and <a href="http://ontolog.cim3.net/cgi-bin/wiki.pl?LeoObrst">Leo Obrst</a>.</p>
]]></content:encoded>
	</item>
<item rdf:about="http://ebiquity.umbc.edu/blogger/2014/01/09/yunsu-lee-phd-proposal-functional-reference-ontology-development/">
	<title>Yunsu Lee PhD proposal: Functional Reference Ontology Development</title>
	<link>http://ebiquity.umbc.edu/blogger/2014/01/09/yunsu-lee-phd-proposal-functional-reference-ontology-development/</link>
	<dc:date>2014-01-09T22:24:25Z</dc:date>
	<dc:creator><![CDATA[Tim Finin]]></dc:creator>
			<dc:subject><![CDATA[Ontologies]]></dc:subject>
		<dc:subject><![CDATA[Semantic Web]]></dc:subject>
	<description><![CDATA[Yunsu Lee will present his dissertation proposal, Functional Reference Ontology Development: a Design Pattern Approach, at 1:00pm on Friday, January 10, 2014 in room 325B of the ITE building at UMBC.]]></description>
	<content:encoded><![CDATA[<div id="tweetbutton4758" class="tw_button" style="clear:left; float: left; margin-right: 10px; margin-top:10px; margin-left: -80;float:left;margin-right:10px;"><a href="http://twitter.com/share?url=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F09%2Fyunsu-lee-phd-proposal-functional-reference-ontology-development%2F&amp;text=Yunsu%20Lee%20PhD%20proposal%3A%20Functional%20Reference%20Ontology%20Development&amp;related=ebiquity&amp;lang=en&amp;count=vertical&amp;counturl=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F09%2Fyunsu-lee-phd-proposal-functional-reference-ontology-development%2F" class="twitter-share-button"  style="width:55px;height:22px;background:transparent url('http://ebiquity.umbc.edu/blogger/wp-content/plugins/wp-tweet-button/tweetn.png') no-repeat  0 0;text-align:left;text-indent:-9999px;display:block;">Tweet</a></div><p><img class="alignnone size-full wp-image-16177" title="Functional Reference Ontology Development: a Design Pattern Approach" alt="" src="http://www.csee.umbc.edu/wp-content/uploads/2014/01/yunsu21.png" width="500" height="216" border="1" /></p>
<h3 style="text-align: center;">Computer Science and Electrical Engineering<br />
University ofÂ Maryland, Baltimore County</h3>
<h3 style="text-align: center;">Ph.D. Dissertation Proposal</h3>
<h2 style="text-align: center;">Functional Reference Ontology Development:<br />a Design Pattern Approach</h2>
<h2 style="text-align: center;">Yunsu Lee</h2>
<h3 style="text-align: center;">1:00pm Friday, January 10, 2014, ITE325b, UMBC</h3>
<p>The next generation of smart manufacturing systems will be developed by composing advanced manufacturing components and IT services introducing new technologies. These new technologies can lead to dramatic improvements in the ability to monitor, control, and optimize all aspects of manufacturing. The ability to compose advanced manufacturing components and IT services enhances agility, resiliency, and productivity of a manufacturing system. In order to make the composition possible, functional knowledge of manufacturing components and IT services should be captured and shared explicitly. Recent researches have shown that a semantically precise and rich reference functional ontology enables effective composition. However, since domains of factories and production networks are large, evolving, and heterogeneous, developing a reference functional ontology is a challenging task. Specifically, conceptual functionality modeling that characterizes various features of manufacturing components and IT services at different levels of abstraction is a difficult task. Even if the reference functional ontology is developed successfully, there will certainly be interoperability issues between the reference functional ontology and local proprietary information models. Firstly, the conceptual conflict issues may arise primarily from the fact that the reference functional ontology does not reflect actual users&#8217; or providers&#8217; conceptualizations. Secondly, structural conflict issues may arise from diverse modeling choices in local, proprietary information models.</p>
<p>The objective of our research is to assess utility of design patterns in addressing the issues in the reference functional ontology development, specifically OWL ontology design patterns (ODPs). To achieve the objective, we will assess inductive approaches to identifying the ODPs, and explore development of a methodology for resolving structural differences between the reference functional ontology and local proprietary information models. The key potential contributions of this work include 1) new method to identify information patterns of functionalities in manufacturing components and IT services, 2) new inductive ODP development process which starts with the pattern definition of the specific functionality concepts, with subsequent grouping of these patterns into more general patterns, and 3) ODP-based ontology transformation to resolve structural conflicts between the reference functional ontology and local proprietary information models.</p>
<p>Committee: Drs. Yun Peng (chair), Tim Finin, Yelena Yesha, Milton Halem, Nenad Ivezic (NIST) and Boonserm Kulvatunyou (NIST)</p>
]]></content:encoded>
	</item>
<item rdf:about="http://ebiquity.umbc.edu/blogger/2014/01/01/google-knowledge-maps-demonstration/">
	<title>Freebase knowledge maps</title>
	<link>http://ebiquity.umbc.edu/blogger/2014/01/01/google-knowledge-maps-demonstration/</link>
	<dc:date>2014-01-01T16:43:49Z</dc:date>
	<dc:creator><![CDATA[Tim Finin]]></dc:creator>
			<dc:subject><![CDATA[Google]]></dc:subject>
		<dc:subject><![CDATA[Semantic Web]]></dc:subject>
	<description><![CDATA[Tweet Google has a very nice demonstration of web application that extracts information from Freebase and displays it on a Google map. It uses the Google Maps JavaScript API and the Freebase knowledge base to find entities and facts associated with places on a map. The source code is available on Github and is just [&#8230;]]]></description>
	<content:encoded><![CDATA[<div id="tweetbutton4745" class="tw_button" style="clear:left; float: left; margin-right: 10px; margin-top:10px; margin-left: -80;float:left;margin-right:10px;"><a href="http://twitter.com/share?url=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F01%2Fgoogle-knowledge-maps-demonstration%2F&amp;text=Freebase%20knowledge%20maps&amp;related=ebiquity&amp;lang=en&amp;count=vertical&amp;counturl=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2014%2F01%2F01%2Fgoogle-knowledge-maps-demonstration%2F" class="twitter-share-button"  style="width:55px;height:22px;background:transparent url('http://ebiquity.umbc.edu/blogger/wp-content/plugins/wp-tweet-button/tweetn.png') no-repeat  0 0;text-align:left;text-indent:-9999px;display:block;">Tweet</a></div><p><img src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2014/01/fkm.png" alt="freebase knowledge map demo" width="500" height="345" class="alignnone size-full wp-image-4750" /></p>
<p>Google has a very nice <a href="http://googleknowledge.github.io/FreebaseMaps/">demonstration</a> of web application that extracts information from Freebase and displays it on a Google map.  It uses the <a href="https://developers.google.com/maps/documentation/javascript/">Google Maps JavaScript API</a> and the <a href="https://en.wikipedia.org/wiki/Freebase">Freebase</a> knowledge base to find entities and facts associated with places on a map. The <a href="https://github.com/googleknowledge/FreebaseMaps">source code</a> is available on Github and is just a small amount of javascript and some css (via <a href="http://lesscss.org/">less</a>) files.</p>
<p><iframe width="500" height="281" src="//www.youtube.com/embed/BOHzSLfmMrQ" frameborder="0" allowfullscreen></iframe></p>
<p>&#8220;The app uses <a href="http://www.w3.org/TR/geolocation-API/">browser&#8217;s geolocation feature</a> to find user&#8217;s location and displays a map of interesting objects that can be found nearby (within 50 000 ft). It uses the <a href="https://developers.google.com/freebase/v1/search-overview">Freebase Search API</a> to find relevant objects. When user clicks on one of the markers, the app calls the <a href="https://developers.google.com/freebase/v1/topic-overview">Freebase Topic API</a> to fetch more information about that object. Once the information is retrieved, it populates a <a href="http://www.purejs.org/">purejs</a> template to display a knowledge card for the user.&#8221;</p>
<p>This sort of application has been done many times before with RDF and the Google approach can be adapted to query an arbitrary RDF resource for custom knowledge bases.</p>
]]></content:encoded>
	</item>
<item rdf:about="http://ebiquity.umbc.edu/blogger/2013/05/23/googles-top-charts-uses-the-knowledge-graph-for-entity-recognition/">
	<title>Google Top Charts uses the Knowledge Graph for entity recognition and disambiguation</title>
	<link>http://ebiquity.umbc.edu/blogger/2013/05/23/googles-top-charts-uses-the-knowledge-graph-for-entity-recognition/</link>
	<dc:date>2013-05-23T13:07:05Z</dc:date>
	<dc:creator><![CDATA[Tim Finin]]></dc:creator>
			<dc:subject><![CDATA[AI]]></dc:subject>
		<dc:subject><![CDATA[Google]]></dc:subject>
		<dc:subject><![CDATA[KR]]></dc:subject>
		<dc:subject><![CDATA[NLP]]></dc:subject>
		<dc:subject><![CDATA[OWL]]></dc:subject>
		<dc:subject><![CDATA[Semantic Web]]></dc:subject>
	<description><![CDATA[Tweet Top Charts is a new feature for Google Trends that identifies the popular searches within a category, i.e., books or actors. What&#8217;s interesting about it, from a technology standpoint, is that it uses Google&#8217;s Knowledge Graph to provide a universe of things and the categories into which they belong. This is a great example [&#8230;]]]></description>
	<content:encoded><![CDATA[<div id="tweetbutton4679" class="tw_button" style="clear:left; float: left; margin-right: 10px; margin-top:10px; margin-left: -80;float:left;margin-right:10px;"><a href="http://twitter.com/share?url=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2013%2F05%2F23%2Fgoogles-top-charts-uses-the-knowledge-graph-for-entity-recognition%2F&amp;text=Google%20Top%20Charts%20uses%20the%20Knowledge%20Graph%20for%20entity%20recognition%20and%20disambiguation&amp;related=ebiquity&amp;lang=en&amp;count=vertical&amp;counturl=http%3A%2F%2Febiquity.umbc.edu%2Fblogger%2F2013%2F05%2F23%2Fgoogles-top-charts-uses-the-knowledge-graph-for-entity-recognition%2F" class="twitter-share-button"  style="width:55px;height:22px;background:transparent url('http://ebiquity.umbc.edu/blogger/wp-content/plugins/wp-tweet-button/tweetn.png') no-repeat  0 0;text-align:left;text-indent:-9999px;display:block;">Tweet</a></div><p><a href="http://www.google.com/trends/topcharts"><img src="http://ebiquity.umbc.edu/blogger/wp-content/uploads/2013/05/tc1.png" title="Google Trends Top Charts present lists of real-world people, places and things ranked in order of search interest. " width="500" height="238" border="1" class="alignnone size-full wp-image-4680" /></a></p>
<p><a href="http://google.com/trends/topcharts">Top Charts</a> is a new feature for Google Trends that identifies the popular searches within a category, i.e., books or actors.  What&#8217;s interesting about it, from a technology standpoint, is that it uses Google&#8217;s <a href="http://www.google.com/insidesearch/features/search/knowledge.html">Knowledge Graph</a> to provide a universe of things and the categories into which they belong.  This is a great example of <i>&#8220;Things, not strings&#8221;</i>, Google&#8217;s clever slogan to explain the importance of the Knowledge Graph.</p>
<p>Here&#8217;s how it&#8217;s explained in in the <a href="https://support.google.com/trends/answer/3076011">Trends Top Charts FAQ</a>.</p>
<blockquote><p> &#8220;Top Charts relies on technology from the Knowledge Graph to identify when search queries seem to be about particular real-world people, places and things. The Knowledge Graph enables our technology to connect searches with real-world entities and their attributes. For example, if you search for ice ice baby, you&#8217;re probably searching for information about the musician Vanilla Ice or his music. Whereas if you search for vanilla ice cream recipe, you&#8217;re probably looking for information about the tasty dessert. Top Charts builds on work we&#8217;ve done so our systems do a better job finding you the information you&#8217;re actually looking for, whether tasty desserts or musicians.&#8221;</p></blockquote>
<p>One thing to note is that the Knowledge Graph, which is said to have more than 18 billion facts about 570 million objects, is that its objects include more than the traditional named entities (e.g., people, places, things).  For example, there is a top chart for <a href="http://www.google.com/trends/topcharts#vm=chart&#038;cid=animals&#038;geo=US&#038;date=201304">Animals</a> that shows that dogs are the most popular animal in Google searches followed by cats (no surprises here) with chickens at number three on the list (could their high rank be due to recipe searches?).  The <i>dog</i> object, in most knowledge representation schemes, would be modeled as a concept or class as opposed to an object or instance.  In some representation systems, the same term (e.g., <i>dog</i>) can be used to refer to both a class of instances (a class that includes <i>Lassie</i>) and also to an instance (e.g., an instance of the class <i>animal types</i>).  Which sense of the term <i>dog</i> is meant (class vs. instance) is determined by the context.  In the semantic web representation language <a href="http://www.w3.org/TR/owl2-overview/">OWL 2</a>, the ability to use the same term to refer to a class or a related instance is called <a href="http://www.w3.org/2007/OWL/wiki/Punning">punning</a>.</p>
<p>Of course, when doing this kind of mapping of terms to objects, we only want to consider concepts that commonly have words or short phrases used to denote them.  Not all concepts do, such as <a href="http://ebiquity.umbc.edu/blogger/2006/11/21/beneath-the-metadata-lie-animals-and-other-beasts/">animals that from a long way off look like flies</a>.</p>
<p>A second observation is that once you have a nice knowledge base like the Knowledge Graph, you have a new problem: how can you recognize mentions of its instances in text.  In the DBpedia knowledge based (derived from Wikipedia) there are nine individuals named <i>Michael Jordan</i> and two of them were professional basketball players in the NBA.  So, when you enter a search query like &#8220;When did Michael Jordan play for Penn&#8221;, we have to use information in the query, its context and what we know about the possible referents (e.g., those nine Michael Jordans) to decide (1) if this is likely to be a reference to any of the objects in our knowledge base, and (2) if so, to which one.  This task, which is a fundamental one in language processing, is not trivial, but luckily, in applications like Top Charts, we don&#8217;t have to do it with perfect accuracy.</p>
<p>Google&#8217;s Top Charts is a simple, but effective, example that demonstrates the potential usefulness of semantic technology to make our information systems better in the near future.</p>
]]></content:encoded>
	</item>
</rdf:RDF>
